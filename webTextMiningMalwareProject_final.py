#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sun Nov 22 00:01:40 2020

@author: austin sanders
"""

import pandas as pd 
from random import seed
from random import randrange
import math
from math import sqrt


malwaredata_scraped = pd.read_csv(r'malwaredata11152020.csv') # The data file needs to be in the current working directory
                                                                # Or a direct link to the file path can be provided

print(malwaredata_scraped)
df_malwaredata_scraped  = pd.DataFrame(malwaredata_scraped)

df_malwaredata_scraped.dropna(subset = ['h1'], inplace=True)  # removes null h1 tag values 
df_malwaredata_scraped = df_malwaredata_scraped.drop_duplicates()  # consolidation and duplicate document elimination
df_malwaredata_scraped = df_malwaredata_scraped.reset_index(drop=True) # reindexes the malware documents after consolidating so that the index
                                                                        # can be used for doc feature (character) vectorization 
unique_url = df_malwaredata_scraped['url'].unique()

df_malwaredata_scraped['type'] = 1


num = 1
docs = []
for value in unique_url:
    exec(f'doc{num} = df_malwaredata_scraped.loc[df_malwaredata_scraped["url"] == value]' )
    docs.append(num)
    num +=1
       

# creates the TF fuction of the TF IDF algorithm: 
def computeTF(characterDict):
    tfDict = {}
    lenDict = len(characterDict)
    for character, count in characterDict.items():
        tfDict[character] = count/float(lenDict)
    return tfDict    
    
#The following parses the h1 tage elements as a dictionary of key value pairs. Key - parsed characters from h1 tages. Value: count of the charcter values for each respective doc. 
#The string functions transforms each document as a vector with character dimensions (features)    
j = 0 
list_dict = []
for num in range(1, len(docs)+1):
    exec(f"""
doc{num} = doc{num}["h1"].values
doc{num} = str(doc{num})
doc{num}.split("/")

for x in doc{num}:
    x = str(x)
    x.split('/')
    print(x)
     
doc{num} = {{i:doc{num}.count(i) for i in doc{num}}}    # gives the frequency of each character as a key value pair 
doc{num} = computeTF(doc{num})
doc{num}.update({{'Type': df_malwaredata_scraped['type'][j]}})
list_dict.append(doc{num})
j += 1
         """
         )



benign_data_crawled = pd.read_csv(r'bengin_scraped_data.csv') 

benign_data_crawled.dropna(subset = ['h1'], inplace=True) 
benign_data_crawled = benign_data_crawled.drop_duplicates()
benign_data_crawled = benign_data_crawled.reset_index(drop=True)
benign_data_crawled['type'] = 0
unique_url = benign_data_crawled['url'].unique()

num = 1
docs2 = []
for value in unique_url:
    exec(f'doc{num} = benign_data_crawled.loc[benign_data_crawled["url"] == value]' )
    docs2.append(num)
    num +=1


j = 0 
for num in range(1, len(docs2)+1):
    exec(f"""
doc{num} = doc{num}["h1"].values
doc{num} = str(doc{num})
doc{num}.split("/")

for x in doc{num}:
    x = str(x)
    x.split('/')
    print(x)
     
doc{num} = {{i:doc{num}.count(i) for i in doc{num}}}
doc{num} = computeTF(doc{num})
doc{num}.update({{'Type': benign_data_crawled['type'][j]}})
list_dict.append(doc{num})
j += 1
         """
         )


# Creates the IDF function of the TF IDF algorithm:
def computeIDF(list_dict):
    idfDict = {}
    N = len(list_dict)
    
    idfDict = dict.fromkeys(list_dict[0].keys(), 0)
    for doc in list_dict:
        for character, val in doc.items():
            if val > 0:
                idfDict[character] += 1
    
    for character, val in idfDict.items():
        idfDict[character] = math.log10(N / float(val))
        
    return idfDict


import numpy as np

dataframe = pd.DataFrame(list_dict)  
dataframe = dataframe.replace(np.nan, 0)
malwareType = dataframe['Type']

dataframe = dataframe.drop(columns = ['Type'])

dataframe = dataframe.to_dict('records')

idfs = computeIDF(dataframe)

def computeTFIDF(dataframe, idfs):
    list_tfidf = []
    for i in range(0, len(dataframe)):
        exec(f"""
tfidf{i} = {{}}
for character, val in dataframe[i].items():
    tfidf{i}[character] = val*idfs[character]
list_tfidf.append(tfidf{i})   
             """
             )
    return list_tfidf


list_tfidf = computeTFIDF(dataframe, idfs)

dataframe = pd.DataFrame(list_tfidf)

dataframe['Type'] = malwareType


dataset = dataframe.values
dataset = dataset.tolist()

import matplotlib.pyplot as plt 
from pandas.plotting import andrews_curves


# Running this at one time will create overlapping plots. To see the plots separatly, the 
# plots need to be executed indivually. 

pd.plotting.andrews_curves(dataframe, "Type", color=('r', 'c')) # This line of code helps visualize differences in 
                                                                    # the benign (0) vs Malicous (1) document vectors


def dataset_minmax(dataset):
	minmax = list()
	for i in range(len(dataset[0])):   
		col_values = [row[i] for row in dataset]  
		value_min = min(col_values)
		value_max = max(col_values)
		minmax.append([value_min, value_max])
	return minmax
    
        
def normalize_dataset(dataset, minmax):
	for row in dataset:
		for i in range(len(row)):
			row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])
 
# Splits a dataset into k folds
def cross_validation_split(dataset, n_folds):   # 2nd function called
	dataset_split = list() # intitalizes the list object for the split dataset
	dataset_copy = list(dataset)
	fold_size = int(len(dataset) / n_folds)   # this dataset in this example creates a fold size of (473/ specified number of folds)
	for _ in range(n_folds): # creates a nested list for the split dataset that is later appended to the list intitalized as dataset_split
		fold = list()
		while len(fold) < fold_size:  
			index = randrange(len(dataset_copy))
			fold.append(dataset_copy.pop(index))  # the index is poped so that the while look has a terminating condition
                                                 
		dataset_split.append(fold)
	return dataset_split
 
# Calculates evaluations metrics

def accuracy_metric(actual, predicted):
    correct = 0 
    truePositive = 0 
    falsePositive = 0 
    trueNegative = 0
    falseNegative = 0
    observedPositive = 0
    observedNegative = 0 
    for i in range(len(actual)):
        if actual[i] == 1:
            observedPositive += 1
        if actual[i] == 0:
            observedNegative +=1         
        if actual[i] == predicted[i]:
            correct += 1
        if actual[i] == 1 and predicted[i] == 1:
            truePositive += 1 
        if actual[i] ==1 and predicted[i] == 0:
            falseNegative += 1
        if actual[i] == 0 and predicted[i] == 1:
            falsePositive +=1
        if actual[i] == 0 and predicted[i] == 0:
            trueNegative +=1
    precision = truePositive/(truePositive + falsePositive)
    recall = truePositive/(truePositive + falseNegative)
    TPR = truePositive/(truePositive + falseNegative)
    specifity = trueNegative/(falsePositive + trueNegative)
    FPR = 1-specifity
    evaluationData = ((correct / float(len(actual))), TPR , specifity, FPR , falsePositive/observedPositive, falseNegative/observedNegative, precision, recall)
    return evaluationData
    
# Evaluates an algorithm using a cross validation split

    
def evaluate_algorithm(dataset, algorithm, n_folds, *args):  # this is the first (1st) function that is called
	folds = cross_validation_split(dataset, n_folds)  # returns a split dataset as a list 
	scores = list()
	for fold in folds:
		train_set = list(folds)
		train_set.remove(fold)
		train_set = sum(train_set, [])
		test_set = list()
		for row in fold:
			row_copy = list(row)
			test_set.append(row_copy)
			row_copy[-1] = None
		predicted = algorithm(train_set, test_set, *args) # this is the 3rd function called -- this calls the KNN algorithm passed
                                                         # to the evaluate_algorithm function
        # visualization will be created for each one of these and confusion metrics
		actual = [row[-1] for row in fold] 
        
		measures = accuracy_metric(actual, predicted) # this is the 4th function called 
		scores.append(measures)
    
	return scores 
    
# Calculates the Euclidean distance between two vectors:
def euclidean_distance(row1, row2):
 	distance = 0.0
 	for i in range(len(row1)-1):
         distance += (row1[i] - row2[i])**2
 	return sqrt(distance)


 
# Locate the most similar neighbors using euclidean distance:
def get_neighbors(train, test_row, num_neighbors):
 	distances = list()
 	for train_row in train:
         dist = euclidean_distance(test_row, train_row) #for the euclidean distance         
         distances.append((train_row, dist))
 	distances.sort(key=lambda tup: tup[1])
 	neighbors = list()
 	for i in range(num_neighbors):
         neighbors.append(distances[i][0])
 	return neighbors
 

# # Manhatten distance for use with the get_neighbors() function:    
# def manhatten_distance(row1, row2):
#     distance = 0.0
#     for i in range(len(row1)-1):
#         distance += abs(row1[i] - row2[i]) 
#     return distance    

# # get_neighbors() function with the Manhatten distance function:
# def get_neighbors(train, test_row, num_neighbors):
#     distances = list()
#     for train_row in train:
#         dist = manhatten_distance(test_row, train_row) #for the manhatten distance  
#         distances.append((train_row, dist))
#     distances.sort(key=lambda tup: tup[1])
#     neighbors = list()
#     for i in range(num_neighbors):
#         neighbors.append(distances[i][0])
#     return neighbors

# Makes a prediction with neighbors
def predict_classification(train, test_row, num_neighbors):
	neighbors = get_neighbors(train, test_row, num_neighbors)
	output_values = [row[-1] for row in neighbors]
	prediction = max(set(output_values), key=output_values.count)
	return prediction
 

# kNN Algorithm
def k_nearest_neighbors(train, test, num_neighbors):
	predictions = list()
	for row in test:
		output = predict_classification(train, row, num_neighbors)
		predictions.append(output)
	return(predictions)




list_scores = []
n_folds = 5
for i in range(1, 5, 1):
    for j in range(3, 51, 1):
        seed(i)
# evaluation metrics:
        num_neighbors = j
        exec(f"""
scores{i}_{j} = evaluate_algorithm(dataset, k_nearest_neighbors, n_folds, num_neighbors)
len_scores{i}_{j} = len(scores{i}_{j})
sum_scores{i}_{j} = [sum(scores) for scores in zip(*scores{i}_{j})] 
avg_scores{i}_{j} = [scores/len_scores{i}_{j} for scores in sum_scores{i}_{j}]
list_scores.append(avg_scores{i}_{j})  
scores{i}_{j} = pd.DataFrame(scores{i}_{j}, columns = ['Accuracy','TPR', 'specificity', 'FPR', 'FP', 'FN', 'Precision', 'Recall'])
     
             """
             )
        
list_scores = pd.DataFrame(list_scores, columns = ['Accuracy','TPR', 'specificity', 'FPR', 'FP', 'FN', 'Precision', 'Recall'])
        
plt.figure()
list_scores.plot()
plt.show;

plt.title('Receiver Operating Characteristic')
plt.scatter(list_scores['FPR'].values, list_scores['TPR'].values)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()


