# This one is used in the report for scraping malicious websites


import scrapy
import pandas as pd
import csv

IPdata = pd.read_csv(r'malwareUrls_only_without_type11012020.csv') # This is where the path to the data file conataining the malicious URLs will go.

df_IPdata = pd.DataFrame(IPdata)

urls1 = df_IPdata['localhost']
urls1 = [i if i.startswith('http') else 'http://' + i for i in urls1]
urls1 = list(urls1)

class MySpider(scrapy.Spider):
    name = 'MaliciousWebScraper'

    start_urls = urls1

    def parse(self, response):

            h1 = response.xpath("//h1").getall()
            url = response.url

            yield {'h1': h1,
                   'url': url}

# To run this crawler, change directory to the directory with this file and type: scrapy crawl MaliciousWebScraper in the terminal